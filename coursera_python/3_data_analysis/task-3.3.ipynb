{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Ансамблевые модели",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Задача классификации ",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "В этом практическом задании вы научитесь работать с ансамблевыми моделями. Мы начнем с задачи классификации итальянского вина на предмет его пренадлежности к одному из трех видов. Загрузите датасет `Wine Data Database` с помощью функции `load_wine` из модуля `sklearn.datasets`.",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "from sklearn.datasets import load_wine\n\nX, y = load_wine(return_X_y=True)",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": "Модель случайного леса для классификации представлена классом `RandomForestClassifier` из модуля `sklearn.ensemble`. Конструктор этого класса содержит аргумент `n_estimators`, который соответствует колличеству базовых алгоритмов в случайном лесе. Целью этого задания будет настройка этого параметра. Сравните модели случайных лесов с различным числом базовых алгоритмов `{1, 5, 10, 20}`. Что происходит с качеством случайного леса на тестовых данных при увеличении этого числа? Ответом на это задание `answer1` является лучшая оценка качества модели, округленная до трех знаков после запятой. Используйте `accuracy` как метрику качества и скользящий контроль `cross_val_score` как метод оценки качества модели. Установите параметр `cv = StratifiedKFold(4)`. Возьмите среднее значение оценки качества. Для каждой из моделей случайного леса используете `random_state=42` при создании нового экземпляра.",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### *РЕШЕНИЕ*",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\n\nmax_score = 0\nmax_n = 0\n\nfor n_estimators in [1, 5, 10, 20]:\n    model = RandomForestClassifier(random_state=42, n_estimators=n_estimators)\n    score = cross_val_score(model, X, y, scoring=\"accuracy\", cv=StratifiedKFold(4))\n    \n    if score.mean() > max_score:\n        max_score = score.mean()\n        max_n = n_estimators\n        \nanswer1 = max_score",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "Далее сравните модель градиентного бустинга `GradientBoostingClassifier` из `sklearn.ensemble` с логистической регрессией `LogisticRegression` из `sklearn.linear_model` на этой выборке. Используете параметр `random_state=42` при создании экземпляров классов. Какая из моделей работает лучше? Приведите лучшую оценку, округленную до трех знаков после запятой, в качестве ответа `answer2` на это задание. Какие выводы из этого можно сделать?",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### *РЕШЕНИЕ*",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nmodel1 = GradientBoostingClassifier(random_state=42)\nmodel2 = LogisticRegression(random_state=42)\n\nscore1 = cross_val_score(model1, X, y, cv=StratifiedKFold(4))\nscore2 = cross_val_score(model2, X, y, cv=StratifiedKFold(4))\n\nanswer2 = max(score1.mean(), score2.mean())",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n"
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": "## Задача регрессии",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Загрузите уже известную вам выборку `Boston House Prices` и разделите ее случайным образом на тренировочную и тестовую выборку. Для этого используете функцию `train_test_split` с параметрами `random_state=54` и `test_size=0.33`. Мы будем сравнивать 4 модели: `RandomForestRegressor`, `GradientBoostingRegressor` из `sklearn.ensemble`, а так же Гребневую регрессию и ЛАССО (`Ridge`, `Lasso` из `sklearn.linear_model`). Обучите каждую модель на тренировочной выборке с параметром `random_state=42` в конструкторе. Какая из моделей показывает наименьшее значение среднеквадратической ошибки на тестовых данных? В качестве ответа `answer3` приведите это значение, округленное до двух цифр после запятой.",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### *РЕШЕНИЕ*",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nraw_df = pd.read_csv('boston.csv', sep=\"\\s+\", skiprows=22, header=None)\nX = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\ny = raw_df.values[1::2, 2]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=54, test_size=0.33)\n\nr_forest = RandomForestRegressor(random_state=42).fit(X_train, y_train).predict(X_test)\ngr_boosting = GradientBoostingRegressor(random_state=42).fit(X_train, y_train).predict(X_test)\nridge = Ridge(random_state=42).fit(X_train, y_train).predict(X_test)\nlasso = Lasso(random_state=42).fit(X_train, y_train).predict(X_test)\n\nanswer3 = min(mean_squared_error(r_forest, y_test), mean_squared_error(gr_boosting, y_test),\n              mean_squared_error(ridge, y_test), mean_squared_error(lasso, y_test))",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "<unknown>:8: SyntaxWarning: invalid escape sequence '\\s'\n<>:8: SyntaxWarning: invalid escape sequence '\\s'\n<>:8: SyntaxWarning: invalid escape sequence '\\s'\n<ipython-input-13-494d8e95f93b>:8: SyntaxWarning: invalid escape sequence '\\s'\n  raw_df = pd.read_csv('boston.csv', sep=\"\\s+\", skiprows=22, header=None)\n"
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": "# Строка с ответами",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "output = \"\"\"Best score (random forest) {0:.3f}\nBest score (other algorithms) {1:.3f}\nBest score (regression) {2:.2f}\"\"\"\nprint(output.format(answer1, answer2, answer3))",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Best score (random forest) 0.972\nBest score (other algorithms) 0.956\nBest score (regression) 8.54\n"
        }
      ],
      "execution_count": 14
    }
  ]
}